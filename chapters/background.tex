\section{Control Flow Graphs}
When compilers convert a source language to the underlying machine code, they first organize the program's statements into a form that is useful for subsequent operations. The compiler constructs a Control Flow Graph (CFG) for each function that separates groups of statements based on the language's available control flow constructs, such as conditional statements or loops. Statements are grouped into basic blocks, and are connected to one another based on their corresponding control flow statements; larger blocks are encouraged to provide more opportunities for program optimizations. After each graph is generated, the compiler converts the statements from each block into the appropriate machine code and outputs each converted block. Control Flow Graphs can also keep track of other information that is useful for later optimizations, such as each basic block's predecessors.

\section{Intermediate Representations}
Some compilers use an Intermediate Representation (IR) for the source language before converting the input program to the appropriate machine code. The IR provides additional information, such as data types, at a lower abstraction level than the input language, and can be processed more easily than the final machine code. Optimizations are often performed after the program is converted to an IR due to having more opportunities to optimize at this level without having to address platform-specific details.

\subsection{LLVM}
The Low Level Virtual Machine (LLVM) IR is commonly used for compiler construction. This IR features instructions similar to those of assembly languages, but also includes features available in higher-level languages. Additional abstractions provided by LLVM include virtual registers, register and variable types, and function headers and calls, removing the overhead needed to maintain calling conventions. Each virtual register in the LLVM IR is unique and can only declared once, a convention known as Single Static Assignment (SSA). LLVM's virtual registers are later mapped to real registers when the program is converted to binary code.

\section{Optimizations}
After creating the CFG for the input program and producing the corresponding IR, a compiler may take one or more optimization passes on the graph. These optimizations are meant to improve program performance without affecting the semantic meaning of the program, and focus on reducing unnecessary code, execution time, and memory usage.

\subsection{SSA Optimization}
Because loading and storing variables from memory can incur time overhead, some compilers minimize the use of memory by storing variables exclusively within registers. This is effective with an IR that enforces SSA because whenever a value is updated, including ones from variables, that value must be assigned to a new virtual register. Optimization using SSA requires recursively searching through a basic block's predecessors to find the last register that contained a desired value. Additionally, the value of a variable may exist in different registers depending on the path of a program, so additional overhead is required to unify different versions of a variable from its predecessors at the beginning of a basic block. Despite the increase in instructions, the reduced time from accessing registers instead of accessing main memory provides significant improvements in speed and memory usage at the cost of larger executable sizes.

\subsection{Constant Propagation}
Certain constants may be known at compilation time within a program. A compiler can replace operands within statements and expressions with known constants, potentially collapsing multiple expressions into single values. Conditions that are replaced with constants may change the structure of the CFG by removing basic blocks that are never traversed.

\subsection{Code Removal and Relocation}
Instructions that do not affect other instructions or have no effect on the program can be removed. Instructions that produce the same result within loops or conditional statements may be relocated to surrounding basic blocks to reduce the amount of redundant calculations.

Pointer Analysis

Types of pointer analyses
